{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encoder-decocder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMc3DNF2VJSujdDQQ41hwdm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnganMitra/PhD/blob/main/Encoder_decocder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUf4LR08xDfw"
      },
      "source": [
        "Multivariate Forecasting with n_past lookback timestamps, n_future predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D0_zrQwl6xA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prLoaeF4o4My",
        "outputId": "43075db7-ed11-4a4b-9d1c-12d94d9d10ad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D2-C8pCpCt9"
      },
      "source": [
        "filePath = \"drive/MyDrive/OASISCode/power/household_power_consumption.txt\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4nrJwitl9tk"
      },
      "source": [
        "df=pd.read_csv(filePath, sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BM4ggS2npeI"
      },
      "source": [
        "df = df.replace('?', np.nan)\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmOMPnUlnrsD"
      },
      "source": [
        "def fill_missing(values):\n",
        "    one_day = 60*24\n",
        "    for row in range(df.shape[0]):\n",
        "        for col in range(df.shape[1]):\n",
        "            if np.isnan(values[col].any()):\n",
        "                values = values[row-one_day,col]\n",
        "df = df.astype('float32')\n",
        "fill_missing(df.values)\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAhAUysLs6LC"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv8iXFaKszW8"
      },
      "source": [
        "Down Sampling from minutes to hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTsqnAAwnuS7"
      },
      "source": [
        "# daily_df = df.resample('D').sum() # day sampling\n",
        "daily_df = df.resample('60T').mean() # 60 min sampling"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc4-KRcgt_gG"
      },
      "source": [
        "daily_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNs83C3EnvC5"
      },
      "source": [
        "split_index = int(len(daily_df) * 0.7)\n",
        "train_df,test_df = daily_df[1:split_index], daily_df[split_index:] "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrJ6lD8xnxy-"
      },
      "source": [
        "train = train_df\n",
        "scalers={}\n",
        "for i in train_df.columns:\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    s_s = scaler.fit_transform(train[i].values.reshape(-1,1))\n",
        "    s_s=np.reshape(s_s,len(s_s))\n",
        "    scalers['scaler_'+ i] = scaler\n",
        "    train[i]=s_s\n",
        "test = test_df\n",
        "for i in train_df.columns:\n",
        "    scaler = scalers['scaler_'+i]\n",
        "    s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
        "    s_s=np.reshape(s_s,len(s_s))\n",
        "    scalers['scaler_'+i] = scaler\n",
        "    test[i]=s_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOREdrDBn07J"
      },
      "source": [
        "def split_series(series, n_past, n_future):\n",
        "  #\n",
        "  # n_past ==> no of past observations\n",
        "  #\n",
        "  # n_future ==> no of future observations \n",
        "  #\n",
        "  X, y = list(), list()\n",
        "  for window_start in range(len(series)):\n",
        "    past_end = window_start + n_past\n",
        "    future_end = past_end + n_future\n",
        "    if future_end > len(series):\n",
        "      break\n",
        "    # slicing the past and future parts of the window\n",
        "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
        "    X.append(past)\n",
        "    y.append(future)\n",
        "  return np.array(X), np.array(y)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN0CR9A0n7IT"
      },
      "source": [
        "n_past = 10\n",
        "n_future = 5 \n",
        "n_features = 7"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRZEktW8n9hk"
      },
      "source": [
        "X_train, y_train = split_series(train.values,n_past, n_future)\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
        "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
        "X_test, y_test = split_series(test.values,n_past, n_future)\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
        "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDQ6pSvooF6-"
      },
      "source": [
        "Sequence to Sequence Model with an Encoder and  Decoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4SqaiwqoBGQ",
        "outputId": "f493aea2-c029-4399-fa35-0fe65b57040d"
      },
      "source": [
        "# E1D1\n",
        "# n_features ==> no of features at each timestep in the data.\n",
        "#\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "\n",
        "#\n",
        "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
        "\n",
        "#\n",
        "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l1)\n",
        "\n",
        "#\n",
        "model_e1d1 = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
        "\n",
        "#\n",
        "model_e1d1.summary()\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 10, 7)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, 100), (None, 43200       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_2 (RepeatVector)  (None, 5, 100)       0           lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 5, 100)       80400       repeat_vector_2[0][0]            \n",
            "                                                                 lstm_6[0][1]                     \n",
            "                                                                 lstm_6[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 5, 7)         707         lstm_7[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 124,307\n",
            "Trainable params: 124,307\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ0uk-g4oTzc"
      },
      "source": [
        "Sequence to sequence model with 2 encoders-decoders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkheLcKRoXDl",
        "outputId": "5b77861a-df41-49a5-8576-39b510efafe4"
      },
      "source": [
        "# E2D2\n",
        "# n_features ==> no of features at each timestep in the data.\n",
        "#\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
        "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "encoder_states2 = encoder_outputs2[1:]\n",
        "#\n",
        "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
        "#\n",
        "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
        "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
        "#\n",
        "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
        "#\n",
        "model_e2d2.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 10, 7)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   [(None, 10, 100), (N 43200       input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   [(None, 100), (None, 80400       lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_3 (RepeatVector)  (None, 5, 100)       0           lstm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  (None, 5, 100)       80400       repeat_vector_3[0][0]            \n",
            "                                                                 lstm_8[0][1]                     \n",
            "                                                                 lstm_8[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  (None, 5, 100)       80400       lstm_10[0][0]                    \n",
            "                                                                 lstm_9[0][1]                     \n",
            "                                                                 lstm_9[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 5, 7)         707         lstm_11[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 285,107\n",
            "Trainable params: 285,107\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ua0plIoaAk"
      },
      "source": [
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
        "history_e1d1=model_e1d1.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])\n",
        "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
        "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB_Tvdq5vjYh"
      },
      "source": [
        "model_e1d1.save_weights(\"e1d1.h5\")\n",
        "model_e2d2.save_weights(\"e2d2.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD0b1SutwKnM"
      },
      "source": [
        "model_e1d1.reset_states()\n",
        "model_e1d1.load_weights(\"e1d1.h5\")\n",
        "\n",
        "model_e2d2.reset_states()\n",
        "model_e2d2.load_weights(\"e2d2.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZRCcw3uogtE"
      },
      "source": [
        "pred_e1d1=model_e1d1.predict(X_test)\n",
        "pred_e2d2=model_e2d2.predict(X_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6QmWpiroj00"
      },
      "source": [
        "Rescaling of predicted outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScfpPPlomE7"
      },
      "source": [
        "for index,i in enumerate(train_df.columns):\n",
        "    scaler = scalers['scaler_'+i]\n",
        "    # pred1_e1d1[:,:,index]=scaler.inverse_transform(pred1_e1d1[:,:,index])\n",
        "    pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\n",
        "    # pred1_e2d2[:,:,index]=scaler.inverse_transform(pred1_e2d2[:,:,index])\n",
        "    pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
        "    y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
        "    y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhdhuXGdoz1W"
      },
      "source": [
        "Comparing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maAnoLCgonoC"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "for index,i in enumerate(train_df.columns):\n",
        "  print(i)\n",
        "  for j in range(1,6):\n",
        "    print(\"Day \",j,\":\")\n",
        "    print(\"MAE-E1D1 : \",mean_absolute_error(y_test[:,j-1,index],pred_e1d1[:,j-1,index]),end=\", \")\n",
        "    print(\"MAE-E2D2 : \",mean_absolute_error(y_test[:,j-1,index],pred_e2d2[:,j-1,index]))\n",
        "  print()\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgZLNu8Er6eo",
        "outputId": "46ba533c-c27a-463b-fc09-2622195018de"
      },
      "source": [
        "y_test[0].shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCsAunf9sYX0",
        "outputId": "8a222a8e-0e6c-4798-a3dd-fbdc1987ebeb"
      },
      "source": [
        "pred_e1d1[0].shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v82tmgxeuar7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}